import os
import warnings
import logging
import asyncio
from dataclasses import dataclass
from getpass import getpass
import time

import openai
import whisper
from pydub import AudioSegment
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters


# —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –∏–º–ø–æ—Ä—Ç–∞ logging
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("httpcore").setLevel(logging.WARNING)


# –ü–æ–¥–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'
os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=FutureWarning)


# ----------------- Configuration ----------------- #
@dataclass
class Config:
    TELEGRAM_TOKEN: str
    OPENAI_API_KEY: str
    WHISPER_MODEL: str = "base"
    GPT_MODEL: str = "gpt-4-turbo"
    AUDIO_CACHE: str = "audio_cache"
    TEMP_TRANSCRIBE: float = 0.2
    TEMP_SUMMARY: float = 0.5

    def __post_init__(self):
        os.makedirs(self.AUDIO_CACHE, exist_ok=True)


# ----------------- Audio Processor ----------------- #
class AudioProcessor:
    def __init__(self, config: Config):
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)

    async def prepare(self, update: Update, status_msg) -> str:
        if not update.message.audio:
            raise ValueError("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ MP3 –∏–ª–∏ WAV.")

        file_name = update.message.audio.file_name
        tg_file = await update.message.audio.get_file()
        file_size = tg_file.file_size / 1024  # in KB
        await status_msg.edit_text(f"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª '{file_name}' ({file_size:.2f} KB)...")

        ext = os.path.splitext(file_name)[1].lower()
        if ext not in ['.mp3', '.wav']:
            raise ValueError("–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ MP3 –∏–ª–∏ WAV.")

        raw_path = os.path.join(self.config.AUDIO_CACHE, f"{tg_file.file_id}{ext}")
        await tg_file.download_to_drive(custom_path=raw_path)
        self.logger.info(f"Downloaded audio to {raw_path}")
        await status_msg.edit_text(f"‚úÖ –§–∞–π–ª '{file_name}' –∑–∞–≥—Ä—É–∂–µ–Ω.")

        if ext == '.mp3':
            await status_msg.edit_text(f"üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è '{file_name}' –∏–∑ MP3 –≤ WAV...")
            wav_path = os.path.splitext(raw_path)[0] + '.wav'
            audio = AudioSegment.from_mp3(raw_path)
            audio.export(wav_path, format="wav")
            self.logger.info(f"Converted MP3 to WAV: {wav_path}")
            os.remove(raw_path)
            await status_msg.edit_text(f"‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: '{os.path.basename(wav_path)}'")
            return wav_path

        return raw_path


# ----------------- Meeting Processor ----------------- #
class MeetingProcessor:
    def __init__(self, config: Config):
        openai.api_key = config.OPENAI_API_KEY
        self.config = config
        self.logger = logging.getLogger(self.__class__.__name__)
        self.logger.info("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper...")
        self.whisper_model = whisper.load_model(config.WHISPER_MODEL)
        self.logger.info("–ú–æ–¥–µ–ª—å Whisper –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

    async def transcribe(self, audio_path: str, status_msg) -> str:
        self.logger.info("–ù–∞—á–∞–ª–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏")
        await status_msg.edit_text("üîç –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.")
        result = await asyncio.to_thread(self.whisper_model.transcribe, audio_path)
        text = result.get('text', '')
        self.logger.info("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        await status_msg.edit_text("‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –≥–æ—Ç–æ–≤–∞.")
        return text

    async def extract_rejects(self, transcript: str, status_msg) -> str:
        self.logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏")
        await status_msg.edit_text("üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞... –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ.")
        prompt = (
            "–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –≤—Å—Ç—Ä–µ—á–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å—Ñ–æ—Ä–º–∏—Ä—É–π –¥–æ–∫—É–º–µ–Ω—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
            "1) –ù–æ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –±—Ä–∞–∫–∞, –ù–ï –ø–æ–¥–ª–µ–∂–∞—â–∏–µ –ø–µ—Ä–µ–¥–∞—á–µ —Å –ö–¶ —Å 12.06:\n"
            "<–ø—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫>\n\n"
            "2) –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –±—Ä–∞–∫–∞, –ù–ï –ø–æ–¥–ª–µ–∂–∞—â–∏–µ –ø–µ—Ä–µ–¥–∞—á–µ —Å –ö–¶ —Å 09.06:\n"
            "<–ø—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫>\n\n"
            "3) –û—Å—Ç–∞–≤–ª—è–µ–º:\n"
            "<—Å–ø–∏—Å–æ–∫ —á–µ—Ä–µ–∑ –¥–µ—Ñ–∏—Å>\n"
            f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è:\n{transcript}\n"
            "–û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–º, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."
        )
        response = await asyncio.to_thread(
            openai.ChatCompletion.create,
            model=self.config.GPT_MODEL,
            messages=[
                {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ —Å–æ–±—Ä–∞–Ω–∏—è."},
                {"role": "user", "content": prompt}
            ],
            temperature=self.config.TEMP_SUMMARY
        )
        doc = response.choices[0].message.content.strip()
        self.logger.info("–î–æ–∫—É–º–µ–Ω—Ç —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –±—Ä–∞–∫–∞ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω")
        await status_msg.edit_text("‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω.")
        return doc


# ----------------- Telegram Bot ----------------- #
class RejectsBot:
    def __init__(self, config: Config):
        self.config = config
        self.audio_proc = AudioProcessor(config)
        self.meeting_proc = MeetingProcessor(config)

        logging.basicConfig(
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            level=logging.INFO
        )
        self.logger = logging.getLogger(self.__class__.__name__)

        self.app = Application.builder().token(config.TELEGRAM_TOKEN).build()
        self.app.add_handler(CommandHandler('start', self.start))
        self.app.add_handler(MessageHandler(filters.AUDIO, self.handle))

    async def start(self, update: Update, context):
        await update.message.reply_text(
            "ü§ñ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –Ø –±–æ—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–µ–π –≤—Å—Ç—Ä–µ—á.\n"
            "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ MP3 –∏–ª–∏ WAV, –∏ —è —Å—Ñ–æ—Ä–º–∏—Ä—É—é –¥–æ–∫—É–º–µ–Ω—Ç —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –±—Ä–∞–∫–∞."
        )

    async def handle(self, update: Update, context):
        status = await update.message.reply_text("üîÑ –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
        audio_path = None
        start_time = time.time()
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∞—É–¥–∏–æ
            audio_path = await self.audio_proc.prepare(update, status)

            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è
            transcript = await self.meeting_proc.transcribe(audio_path, status)

            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π –±—Ä–∞–∫–∞
            document = await self.meeting_proc.extract_rejects(transcript, status)

            # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            duration = time.time() - start_time
            await status.edit_text(f"üìÑ –ì–æ—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç:\n{document}\n\n–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {duration:.2f} —Å–µ–∫—É–Ω–¥.")
        except ValueError as e:
            await status.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        except openai.error.OpenAIError as e:
            await status.edit_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenAI API. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        except Exception as e:
            self.logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            await status.edit_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        finally:
            if audio_path and os.path.exists(audio_path):
                try:
                    os.remove(audio_path)
                    self.logger.info(f"–£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª {audio_path}")
                except Exception as e:
                    self.logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª {audio_path}: {e}")

    def run(self):
        self.logger.info("RejectsBot –∑–∞–ø—É—â–µ–Ω")
        self.app.run_polling()


# ----------------- Entry Point ----------------- #
if __name__ == '__main__':
    config = Config(
        TELEGRAM_TOKEN=getpass('Telegram Token: '),
        OPENAI_API_KEY=getpass('OpenAI API Key: ')
    )
    bot = RejectsBot(config)
    bot.run()
    